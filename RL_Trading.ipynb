{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e37fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e799662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvTest(gym.Env):\n",
    "    def __init__(self, balance=100, spread=0.001, max_variation=0.00005, simulation_duration=\"10\", nb_stock=10):\n",
    "        self.spread = spread # valeur du spread\n",
    "        self.max_variation = max_variation # variation maximale de la courbe en pourcentage\n",
    "        self.simulation_duration = simulation_duration # durée de la simulation demandées\n",
    "        self.nb_stock = 10\n",
    "        self.action_spaces = spaces.Discrete(3) # 0 = achat, 1 = nothing, 2 = vendre\n",
    "        self.observation_spaces = spaces.Box(low=-np.inf,\n",
    "                                           high=np.inf,\n",
    "                                           shape=(2,),\n",
    "                                           dtype=np.float32)\n",
    "        \n",
    "        self.starting_balance = balance # valeur du porte feuille\n",
    "        self.timestep = 1.0 # simulation sur un pas de 1 seconde\n",
    "        self.max_time = self.timeConverter(self.simulation_duration) # temps maximum d'un épisode\n",
    "        \n",
    "        np.set_printoptions(precision=5)\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"effectue un 'step' dans la simulation\"\"\"\n",
    "        \n",
    "        if self.current_time >= self.max_time:\n",
    "            self.done = True\n",
    "        self.current_time += self.timestep\n",
    "        \n",
    "        self.checkPos(action)\n",
    "                \n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        traitement de l'action à faire\n",
    "        gestion des rewards en fonction de l'action\n",
    "        \n",
    "        \"\"\"\n",
    "        self.generateCurveData()\n",
    "        self.setObservations()       \n",
    "        print(f\" **** done : {self.done} - current_time : {self.current_time} - max_time : {self.max_time}****\")\n",
    "        return self.next_state, self.reward, self.done, self.info\n",
    "    \n",
    "                      \n",
    "    def reset(self):\n",
    "        \"\"\"Reinitialise les variables modifiable\"\"\"\n",
    "        self.current_balance = self.starting_balance\n",
    "        self.curve_values = [] \n",
    "        self.current_curve_value = self.initializeCurve()\n",
    "        self.profit_loss = 0.0\n",
    "        \n",
    "        self.current_time = 0.0\n",
    "        self.reward = 0.0\n",
    "        self.done = False\n",
    "        self.info = {}\n",
    "        \n",
    "        self.state = np.zeros(self.observation_spaces.shape[0])\n",
    "        self.next_state = self.state\n",
    "        last_action = 1 # derniere action effectué par l'agent, initialisé à 1 \"nothing\"\n",
    "        self.last_buy_or_sell_value = False # valeur de la courbe lors de l'achat ou de la vente\n",
    "        \n",
    "        self.pos = \"Pas de position\"\n",
    "        \n",
    "        \n",
    "        return self.next_state, self.reward, self.done, self.info\n",
    "    \n",
    "        \n",
    "    def render(self):\n",
    "        \"\"\"Affiche l'environnement, dans notre cas la courbe\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def initializeCurve(self):\n",
    "        \"\"\"Initialise une courbe entre les valeurs min et max\"\"\"\n",
    "        minimum_value = 1.053\n",
    "        maximum_value = 1.062\n",
    "        value = rnd.uniform(minimum_value, maximum_value)\n",
    "        self.curve_values.append(value)\n",
    "        return np.array([value])\n",
    "    \n",
    "    def generateCurveData(self):\n",
    "        \"\"\"génère la prochaine valeur de la courbe en fonction du taux de variation\n",
    "        sauvegarde la valeur dans l'historique\"\"\"\n",
    "        variation = rnd.uniform(-self.max_variation, self.max_variation)\n",
    "        self.current_curve_value += self.current_curve_value * variation\n",
    "        self.saveCurveData()\n",
    "    \n",
    "    def saveCurveData(self):\n",
    "        \"\"\"Sauvegarde les données de la courbe dans une liste\"\"\"\n",
    "        self.curve_values.append(self.current_curve_value)\n",
    "    \n",
    "    def updateProfitAndLoss(self, action):\n",
    "        if self.last_buy_or_sell == False: # Si l'agent n'a jamais acheté ou vendu\n",
    "            return 0.0\n",
    "        \"\"\"\n",
    "        gestion des profit et des pertes en fonction :\n",
    "        - valeur de la courbe lors de l'achat ou vente\n",
    "        - spread\n",
    "        - valeur d'un pips ?\n",
    "        - nb de stock acheté ou vendu ?\n",
    "        \"\"\"     \n",
    "        pass\n",
    "    \n",
    "    def setObservations(self):\n",
    "        \"\"\"Gestion des observations\"\"\"\n",
    "        self.next_state[0] = self.curve_values[-1] ## Valeur actuelle de la courbe/last value de l'histo\n",
    "        self.next_state[1] = self.profit_loss ## Valeur actuelle des profits/pertes\n",
    "              \n",
    "    def setReward(self):\n",
    "        \"\"\"Gestion des rewards\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def checkPos(self, action):\n",
    "        if action == 0:\n",
    "            if self.pos == \"Pas de position\":\n",
    "                print(f\"Achat de {self.nb_stock} stocks à {self.current_curve_value}\")\n",
    "                self.pos = \"Achat\"\n",
    "                self.last_action = 0\n",
    "                self.last_buy_or_sell_value = np.array([self.current_curve_value])\n",
    "            elif self.pos == \"Vente\":\n",
    "                print(f\"Fin de la position de vente de {self.nb_stock} stocks à {self.last_buy_or_sell_value}\")\n",
    "                self.pos = \"Pas de position\"\n",
    "                self.last_action = 0\n",
    "                self.last_buy_or_sell_value = False\n",
    "            else:\n",
    "                self.last_action = 0\n",
    "\n",
    "        if action == 2:\n",
    "            if self.pos == \"Pas de position\":\n",
    "                print(f\"Vente de {self.nb_stock} stocks à {self.current_curve_value}\")\n",
    "                self.pos = \"Vente\"\n",
    "                self.last_action = 2\n",
    "                self.last_buy_or_sell_value = np.array([self.current_curve_value])\n",
    "            elif self.pos == \"Achat\":\n",
    "                print(f\"Fin de la position d'achat de {self.nb_stock} stocks à {self.last_buy_or_sell_value}\")\n",
    "                self.pos = \"Pas de position\"\n",
    "                self.last_action = 2\n",
    "                self.last_buy_or_sell_value = False\n",
    "            else:\n",
    "                self.last_action = 2\n",
    "\n",
    "        if action == 1:\n",
    "            self.last_action = 1\n",
    "    \n",
    "    def timeConverter(self, time):\n",
    "        \"\"\"Convertie la durée entrée manuellement\n",
    "        Renvois la durée maximale en seconde (ou en fonction du time step)\"\"\"\n",
    "        number = \"\"\n",
    "        value = \"\"\n",
    "        for string in time:\n",
    "            if string.isdigit():\n",
    "                number += string\n",
    "            else:\n",
    "                value += string\n",
    "\n",
    "        if not self.translate(value):\n",
    "            print(\"Durée de simulation incorrect...\")\n",
    "            exit() # ajouter la gestion de mauvaises données\n",
    "        time_converted = int(number) * self.translate(value)\n",
    "        return time_converted\n",
    "    \n",
    "    def translate(self, value):\n",
    "        \"\"\"fonction qui permet de traduire et la renvoie en seconde\"\"\"\n",
    "        \n",
    "        ## Constantes de temps en secondes\n",
    "        SECONDE = 1.0\n",
    "        MINUTE = 60.0\n",
    "        HOUR = 60.0 * MINUTE\n",
    "        DAY = 24.0 * HOUR\n",
    "        WEEK = 7.0 * DAY\n",
    "        MONTH = 30.0 * DAY\n",
    "        YEAR = 365.0 * DAY\n",
    "        \n",
    "        d = {\"seconde\" : [\"s\", \"seconde\", \"secondes\", \"sec\", \"secs\"],\n",
    "            \"minute\" : [\"m\", \"min\", \"minute\", \"minutes\", \"mins\", \"minutes\"],\n",
    "            \"hour\" : [\"h\", \"heure\", \"hour\", \"hours\", \"heures\"],\n",
    "            \"day\" : [\"d\", \"j\", \"jour\", \"day\", \"jours\"],\n",
    "            \"week\" : [\"w\", \"week\", \"semaine\", \"weeks\", \"semaines\"],\n",
    "            \"year\" : [\"y\", \"year\", \"année\", \"annee\", \"an\", \"années\", \"years\"]\n",
    "            }\n",
    "\n",
    "        for key in d.keys():\n",
    "            if value.lower() in key:\n",
    "                if key == \"seconde\":\n",
    "                    return SECONDE\n",
    "                elif key == \"minute\":\n",
    "                    return MINUTE\n",
    "                elif key == \"hour\":\n",
    "                    return HOUR\n",
    "                elif key == \"day\":\n",
    "                    return DAY\n",
    "                elif key == \"week\":\n",
    "                    return WEEK\n",
    "                elif key == \"year\":\n",
    "                    return YEAR\n",
    "                \n",
    "        return False\n",
    "\n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def act(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ada59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env observation spaces : (2,)\n",
      "env action spaces : 3\n",
      "\n",
      " **** done : False - current_time : 1.0 - max_time : 10.0****\n",
      "Achat de 10 stocks à [1.05482]\n",
      " **** done : False - current_time : 2.0 - max_time : 10.0****\n",
      "Fin de la position d'achat de 10 stocks à [[1.05482]]\n",
      " **** done : False - current_time : 3.0 - max_time : 10.0****\n",
      "Achat de 10 stocks à [1.05491]\n",
      " **** done : False - current_time : 4.0 - max_time : 10.0****\n",
      " **** done : False - current_time : 5.0 - max_time : 10.0****\n",
      "Fin de la position d'achat de 10 stocks à [[1.05491]]\n",
      " **** done : False - current_time : 6.0 - max_time : 10.0****\n",
      "Vente de 10 stocks à [1.05501]\n",
      " **** done : False - current_time : 7.0 - max_time : 10.0****\n",
      " **** done : False - current_time : 8.0 - max_time : 10.0****\n",
      " **** done : False - current_time : 9.0 - max_time : 10.0****\n",
      " **** done : False - current_time : 10.0 - max_time : 10.0****\n",
      " **** done : True - current_time : 11.0 - max_time : 10.0****\n"
     ]
    }
   ],
   "source": [
    "env = EnvTest(simulation_duration=\"10\")\n",
    "agent = Agent()\n",
    "print(f\"env observation spaces : {env.observation_spaces.shape}\")\n",
    "print(f\"env action spaces : {env.action_spaces.n}\")\n",
    "print()\n",
    "num_action = env.action_spaces.n\n",
    "num_observation = env.observation_spaces.shape[0]\n",
    "\n",
    "nb_max_episode = 1\n",
    "\n",
    "for episode in range(nb_max_episode):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_spaces.sample()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        #print(f\"episode : {episode+1} - score total : {score}\")\n",
    "        \n",
    "        score += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            #env.render()\n",
    "            #print(f\"episode : {episode+1} - score total : {score}\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4aba7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderImbalanceEnv(gym.Env):\n",
    "    def __init__(self, data, lookback, fee):\n",
    "        self.data = data\n",
    "        self.lookback = lookback\n",
    "        self.fee = fee\n",
    "        self.action_space = spaces.Discrete(3) # 0 = sell, 1 = hold, 2 = buy\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(lookback, 3), dtype=np.float32)\n",
    "        self.reset()\n",
    "        \n",
    "        self.temp_data = []\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.balance *= 1 + reward\n",
    "            self.shares -= self.shares * 2\n",
    "        elif action == 2:\n",
    "            self.balance *= 1 + reward\n",
    "            self.shares += self.balance * 0.5 / self.data[self.current_step]\n",
    "        \n",
    "        self.get_rewards(action)\n",
    "        print(f\"action : {action} - balance : {self.balance} - shares : {self.shares}\")\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        obs = self._next_observation()\n",
    "        print(f\"observation : {obs}\")\n",
    "        return obs, self.reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = 1.0\n",
    "        self.shares = 0.0\n",
    "        \n",
    "        self.reward = 0.0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = np.array([\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 0],\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 1],\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 2]\n",
    "        ]).T\n",
    "        return obs\n",
    "    \n",
    "    def get_rewards(self, action):\n",
    "        # récompense lorsque l'agent achète ou vend\n",
    "        if action == 0 or action == 2:\n",
    "            self.reward = (self.data[self.current_step+1] - self.data[self.current_step]) / self.data[self.current_step] - self.fee\n",
    "        else:\n",
    "            reward = (self.data[self.current_step+1] - self.data[self.current_step]) / self.data[self.current_step]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b141bad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     12\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 13\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Action=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Reward=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Balance=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mbalance\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shares=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mshares\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn [2], line 14\u001b[0m, in \u001b[0;36mOrderImbalanceEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbalance \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mreward\u001b[49m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshares \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshares \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reward' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# generate sample data\n",
    "data = np.random.normal(100, 10, size=(1000, 3))\n",
    "\n",
    "# create environment\n",
    "env = OrderImbalanceEnv(data, lookback=10, fee=0.01)\n",
    "\n",
    "# reset environment and get initial observation\n",
    "obs = env.reset()\n",
    "\n",
    "# take random actions for 100 time steps\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"Step {i+1}: Action={action}, Reward={reward:.4f}, Balance={env.balance:.4f}, Shares={env.shares:.4f}\")\n",
    "\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(i+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f976a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
