{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebae27eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f686a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderImbalanceEnv(gym.Env):\n",
    "    def __init__(self, data, lookback, fee):\n",
    "        self.data = data\n",
    "        self.lookback = lookback\n",
    "        self.fee = fee\n",
    "        self.action_space = spaces.Discrete(3) # 0 = sell, 1 = hold, 2 = buy\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(lookback, 3), dtype=np.float32)\n",
    "        self.reset()\n",
    "        \n",
    "        self.temp_data = []\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.balance *= 1 + reward\n",
    "            self.shares -= self.shares * 2\n",
    "        elif action == 2:\n",
    "            self.balance *= 1 + reward\n",
    "            self.shares += self.balance * 0.5 / self.data[self.current_step]\n",
    "        \n",
    "        self.get_rewards(action)\n",
    "        print(f\"action : {action} - balance : {self.balance} - shares : {self.shares}\")\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        obs = self._next_observation()\n",
    "        print(f\"observation : {obs}\")\n",
    "        return obs, self.reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = 1.0\n",
    "        self.shares = 0.0\n",
    "        \n",
    "        self.reward = 0.0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = np.array([\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 0],\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 1],\n",
    "            self.data[self.current_step - self.lookback:self.current_step, 2]\n",
    "        ]).T\n",
    "        return obs\n",
    "    \n",
    "    def get_rewards(self, action):\n",
    "        # récompense lorsque l'agent achète ou vend\n",
    "        if action == 0 or action == 2:\n",
    "            self.reward = (self.data[self.current_step+1] - self.data[self.current_step]) / self.data[self.current_step] - self.fee\n",
    "        else:\n",
    "            reward = (self.data[self.current_step+1] - self.data[self.current_step]) / self.data[self.current_step]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c284fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvTest(gym.Env):\n",
    "    def __init__(self, balance=100, spread=0.001, max_variation=0.05, simulation_duration=\"10s\"):\n",
    "        self.spread = spread # valeur du spread\n",
    "        self.max_variation = max_variation # variation maximale de la courbe en pourcentage\n",
    "        self.simulation_duration = simulation_duration # durée de la simulation demandées\n",
    "        self.action_space = spaces.Discrete(3) # 0 = sell, 1 = hold, 2 = buy\n",
    "        self.observation_space = spaces.Box(low=0.0,\n",
    "                                           high=2.0,\n",
    "                                           shape=(1,),\n",
    "                                           dtype=np.float32)\n",
    "        \n",
    "        self.balance = balance # valeur du porte feuille\n",
    "        self.curve_values = [] # historique des données\n",
    "        self.current_curve_value = self.initializeCurve() # valeur actuelle de la courbe\n",
    "        \n",
    "        \n",
    "        self.timestep = 1.0 # simulation sur un pas de 1 seconde\n",
    "        self.current_time = 0.0 # temps actuel de la simulation\n",
    "        self.max_time = self.timeConverter(self.simulation_duration) # temps maximum d'un épisode\n",
    "        \n",
    "        self.reward = 0.0\n",
    "        self.done = False\n",
    "        \n",
    "        self.last_state = np.zeros(self.observation_space.shape[0])\n",
    "        self.state = self.last_state\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"effectue un 'step' dans la simulation\"\"\"\n",
    "        \n",
    "        if self.current_time >= self.max_time:\n",
    "            self.done = True\n",
    "        self.current_time += self.timestep\n",
    "        \n",
    "        next_state = np.zeros(3)\n",
    "        info = {}\n",
    "        return next_state, self.reward, self.done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.balance = balance\n",
    "        self.curve_values = [] \n",
    "        self.current_curve_value = self.initializeCurve()\n",
    "        \n",
    "        self.current_time = 0.0\n",
    "        self.reward = 0.0\n",
    "        self.done = False\n",
    "        \n",
    "        self.last_state = np.zeros(1) \n",
    "        self.state = self.last_state\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "        \n",
    "    def initializeCurve(self):\n",
    "        \"\"\"Initialise une courbe qui entre les valeurs min et max\"\"\"\n",
    "        minimum_value = 1.055\n",
    "        maximum_value = 1.06\n",
    "        value = rnd.uniform(minimum_value, maximum_value)\n",
    "        self.curve_values.append(value)\n",
    "        return value\n",
    "    \n",
    "    def generateCurveData(self):\n",
    "        \"\"\"génère la prochaine valeur de la courbe en fonction du taux de variation\n",
    "        sauvegarde la valeur dans l'historique\"\"\"\n",
    "        variation = rnd.uniform(-self.max_variation, self.max_variation)\n",
    "        self.current_curve_value += variation\n",
    "        saveCurveData()\n",
    "    \n",
    "    def saveCurveData(self):\n",
    "        \"\"\"Sauvegarde les données de la courbe dans une liste\"\"\"\n",
    "        self.curve_values.append(self.current_curve_value)\n",
    "        \n",
    "    def timeConverter(self, time):\n",
    "        \"\"\"Convertie la durée entrée manuellement\n",
    "        Renvois la durée maximale en seconde (ou en fonction du time step)\"\"\"\n",
    "        number = \"\"\n",
    "        value = \"\"\n",
    "        for string in time:\n",
    "            if string.isdigit():\n",
    "                number += string\n",
    "            else:\n",
    "                value += string\n",
    "\n",
    "        if not self.translate(value):\n",
    "            print(\"Durée de simulation incorrect...\")\n",
    "            return None\n",
    "        time_converted = int(number) * self.translate(value)\n",
    "        return time_converted\n",
    "    \n",
    "    def translate(self, value):\n",
    "        \"\"\"fonction qui permet de traduire et la renvoie en seconde\"\"\"\n",
    "        \n",
    "        ## Constantes de temps en secondes\n",
    "        SECONDE = 1.0\n",
    "        MINUTE = 60.0\n",
    "        HOUR = 60.0 * MINUTE\n",
    "        DAY = 24.0 * HOUR\n",
    "        WEEK = 7.0 * DAY\n",
    "        MONTH = 30.0 * DAY\n",
    "        YEAR = 365.0 * DAY\n",
    "        \n",
    "        d = {\"seconde\" : [\"s\", \"seconde\", \"secondes\", \"sec\", \"secs\"],\n",
    "            \"minute\" : [\"m\", \"min\", \"minute\", \"minutes\", \"mins\", \"minutes\"],\n",
    "            \"hour\" : [\"h\", \"heure\", \"hour\", \"hours\", \"heures\"],\n",
    "            \"day\" : [\"d\", \"j\", \"jour\", \"day\", \"jours\"],\n",
    "            \"week\" : [\"w\", \"week\", \"semaine\", \"weeks\", \"semaines\"],\n",
    "            \"year\" : [\"y\", \"year\", \"année\", \"annee\", \"an\", \"années\", \"years\"]\n",
    "            }\n",
    "\n",
    "        for key in d.keys():\n",
    "            if value.lower() in key:\n",
    "                if key == \"seconde\":\n",
    "                    return MINUTE\n",
    "                elif key == \"minute\":\n",
    "                    return MINUTE\n",
    "                elif key == \"hour\":\n",
    "                    return HOUR\n",
    "                elif key == \"day\":\n",
    "                    return DAY\n",
    "                elif key == \"week\":\n",
    "                    return WEEK\n",
    "                elif key == \"year\":\n",
    "                    return YEAR\n",
    "                \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1f136c73",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EnvTest' object has no attribute 'observation_spaces'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvTest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs space : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m num_action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn [143], line 24\u001b[0m, in \u001b[0;36mEnvTest.__init__\u001b[1;34m(self, balance, spread, max_variation, simulation_duration)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_spaces\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_state\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EnvTest' object has no attribute 'observation_spaces'"
     ]
    }
   ],
   "source": [
    "env = EnvTest()\n",
    "print(f\"obs space : {env.observation_space.shape}\")\n",
    "num_action = env.observation_space.shape[0]\n",
    "for i in range(15):\n",
    "    obs, r, d, i = env.step(15)\n",
    "    print(f\"obs : {obs} - reward : {r} - done : {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c8e1d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp data : [0. 0. 0.]\n",
      "temp data : [4770. 6292. 2823.]\n",
      "action : 1 - balance : 1.0 - shares : 0.0\n",
      "observation : []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], shape=(0, 3), dtype=float64), 0.0, False, {})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def act(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b8fc85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     12\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 13\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Action=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Reward=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Balance=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mbalance\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shares=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mshares\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn [2], line 14\u001b[0m, in \u001b[0;36mOrderImbalanceEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbalance \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mreward\u001b[49m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshares \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshares \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reward' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# generate sample data\n",
    "data = np.random.normal(100, 10, size=(1000, 3))\n",
    "\n",
    "# create environment\n",
    "env = OrderImbalanceEnv(data, lookback=10, fee=0.01)\n",
    "\n",
    "# reset environment and get initial observation\n",
    "obs = env.reset()\n",
    "\n",
    "# take random actions for 100 time steps\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"Step {i+1}: Action={action}, Reward={reward:.4f}, Balance={env.balance:.4f}, Shares={env.shares:.4f}\")\n",
    "\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(i+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0dfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
